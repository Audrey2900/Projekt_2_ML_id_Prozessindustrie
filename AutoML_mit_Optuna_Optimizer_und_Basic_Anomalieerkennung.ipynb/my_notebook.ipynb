{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41211ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import accuracy_score, recall_score, average_precision_score, f1_score\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2bcfb8",
   "metadata": {},
   "source": [
    "# Z-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08c45a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore_detect(data: pd.DataFrame, feature_cols, threshold=3.0):\n",
    "    \n",
    "    out = data.copy()\n",
    "    out[\"is_anomaly_z\"] = False\n",
    "\n",
    "    X = out[feature_cols]\n",
    "\n",
    "    mu = X.mean(axis=0)\n",
    "    sd = X.std(axis=0, ddof=0).replace(0, np.nan)\n",
    "\n",
    "    Z = (X - mu) / sd\n",
    "    out[\"is_anomaly_z\"] = (Z.abs() > threshold).any(axis=1).fillna(False)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc77985c",
   "metadata": {},
   "source": [
    "# OCSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11fc3cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocsvm_fit_predict(\n",
    "    data: pd.DataFrame,\n",
    "    feature_cols,\n",
    "    nu=0.01,\n",
    "    kernel=\"rbf\",\n",
    "    gamma=\"scale\",\n",
    "):\n",
    "\n",
    "    out = data.copy()\n",
    "    X = out[feature_cols].to_numpy()\n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    Xs = scaler.fit_transform(X)\n",
    "\n",
    "    model = OneClassSVM(nu=nu, kernel=kernel, gamma=gamma)\n",
    "    model.fit(Xs)\n",
    "\n",
    "    score_normal = model.decision_function(Xs).ravel()\n",
    "    score_anom = -score_normal\n",
    "    pred = model.predict(Xs)\n",
    "\n",
    "    out[\"ocsvm_score\"] = score_anom\n",
    "    out[\"is_anomaly_ocsvm\"] = (pred == -1)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075126cb",
   "metadata": {},
   "source": [
    "# IForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d579f1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iforest_fit_predict(\n",
    "    data: pd.DataFrame,\n",
    "    feature_cols,\n",
    "    n_estimators=300,\n",
    "    max_samples=0.8,\n",
    "    contamination=0.01,\n",
    "    max_features=1.0,\n",
    "    bootstrap=False,\n",
    "    random_state=42,\n",
    "):\n",
    "\n",
    "    out = data.copy()\n",
    "    X = out[feature_cols].to_numpy()\n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    Xs = scaler.fit_transform(X)\n",
    "\n",
    "    model = IsolationForest(\n",
    "        n_estimators=n_estimators,\n",
    "        max_samples=max_samples,\n",
    "        contamination=contamination,\n",
    "        max_features=max_features,\n",
    "        bootstrap=bootstrap,\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    model.fit(Xs)\n",
    "\n",
    "    score_normal = model.decision_function(Xs)\n",
    "    score_anom = -score_normal\n",
    "    pred = model.predict(Xs)\n",
    "\n",
    "    out[\"if_score\"] = score_anom\n",
    "    out[\"is_anomaly_if\"] = (pred == -1)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3a5ac8",
   "metadata": {},
   "source": [
    "# SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c31756f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def som_anomaly(\n",
    "    data: pd.DataFrame,\n",
    "    feature_cols,\n",
    "    m=10,\n",
    "    n=10,\n",
    "    k=3,\n",
    "    train_quantile=0.995,\n",
    "    n_iter=2000,\n",
    "    alpha=0.3,\n",
    "    sigma=3.0,\n",
    "    random_state=42,\n",
    "):\n",
    "\n",
    "    out = data.copy()\n",
    "    X = out[feature_cols].to_numpy()\n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    Xs = scaler.fit_transform(X)\n",
    "\n",
    "    # ---------- SOM Training ----------\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    N, D = Xs.shape\n",
    "    W = rng.normal(0, 1, size=(m * n, D))\n",
    "    coords = np.array([(i, j) for i in range(m) for j in range(n)], dtype=float)\n",
    "\n",
    "    for t in range(n_iter):\n",
    "        x = Xs[rng.integers(0, N)]\n",
    "        d = np.linalg.norm(W - x, axis=1)\n",
    "        bmu = np.argmin(d)\n",
    "\n",
    "        a_t = alpha * (1 - t / max(1, n_iter))\n",
    "        s_t = sigma * (1 - t / max(1, n_iter))\n",
    "        s_t = max(1e-6, s_t)\n",
    "\n",
    "        dist_grid = np.linalg.norm(coords - coords[bmu], axis=1)\n",
    "        h = np.exp(-(dist_grid**2) / (2 * s_t**2))\n",
    "        W += a_t * h[:, None] * (x - W)\n",
    "\n",
    "    # ---------- Anomaly Score ----------\n",
    "    d = np.linalg.norm(Xs[:, None, :] - W[None, :, :], axis=2)\n",
    "    part = np.partition(d, kth=k-1, axis=1)[:, :k]\n",
    "    scores = part.mean(axis=1)\n",
    "\n",
    "    thr = np.quantile(scores, train_quantile)\n",
    "\n",
    "    out[\"som_score\"] = scores\n",
    "    out[\"is_anomaly_som\"] = scores > thr\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8d7355",
   "metadata": {},
   "source": [
    "# Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e424c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Pfad zum aktuellen Notebook-Verzeichnis\n",
    "current_path = Path().resolve()\n",
    "\n",
    "# Eine Ebene nach oben gehen\n",
    "parent_path = current_path.parent\n",
    "\n",
    "# Pfad zur CSV-Datei zusammensetzen\n",
    "file_path = parent_path / \"data\" / \"SmA-Four-Tank-Batch-Process_V2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5ab59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path, delimiter=\";\")\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "# Anomalien markieren\n",
    "df[\"Anomalie\"] = (df[\"DeviationID ValueY\"] != 1).astype(int)\n",
    "\n",
    "# Optional: Prozessschritt filtern\n",
    "df = df[df[\"CuStepNo ValueY\"] == 8]\n",
    "\n",
    "# Features und Label trennen\n",
    "drop_cols = [\"timestamp\", \"DeviationID ValueY\"]\n",
    "label_col = \"Anomalie\"\n",
    "\n",
    "X_all = df.drop(columns=drop_cols + [label_col])\n",
    "y_all = df[label_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "800d1245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Train/Test Split\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=0.1, random_state=42, stratify=y_all\n",
    ")\n",
    "\n",
    "# 2. Split in Training und Validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# 3. Testdaten\n",
    "X_test = X_test.values\n",
    "y_test = y_test.values\n",
    "\n",
    "# --- Nur Good-Daten für Training behalten ---\n",
    "X_train = X_train[y_train == 0]\n",
    "X_train = X_train.values\n",
    "X_val = X_val.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da6f62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bestes Modell: zscore mit F1=0.4378\n",
      "Beste Parameter: {'threshold': 2.5}\n"
     ]
    }
   ],
   "source": [
    "# --- Feature-Spalten ---\n",
    "feature_cols = X_train.columns if isinstance(X_train, pd.DataFrame) else range(X_train.shape[1])\n",
    "\n",
    "# --- Modelle & Hyperparameter-Raster ---\n",
    "models = {\n",
    "    \"zscore\": {\n",
    "        \"func\": zscore_detect,\n",
    "        \"params\": {\"threshold\": [2.5]}\n",
    "        # \"params\": {\"threshold\": [2.5, 3.0, 3.5, 4.0]}\n",
    "    },\n",
    "    \"ocsvm\": {\n",
    "        \"func\": ocsvm_fit_predict,\n",
    "        \"params\": {\n",
    "            \"nu\": [0.01],\n",
    "            \"kernel\": [\"rbf\"],\n",
    "            \"gamma\": [\"scale\"]\n",
    "            # \"nu\": [0.01, 0.05, 0.1, 0.2],\n",
    "            # \"kernel\": [\"rbf\", \"linear\"],\n",
    "            # \"gamma\": [\"scale\", \"auto\"]\n",
    "        }\n",
    "    },\n",
    "    \"iforest\": {\n",
    "        \"func\": iforest_fit_predict,\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100],\n",
    "            \"max_samples\": [0.5],\n",
    "            \"contamination\": [0.01],\n",
    "            \"max_features\": [0.5]\n",
    "            # \"n_estimators\": [100, 300],\n",
    "            # \"max_samples\": [0.5, 0.8],\n",
    "            # \"contamination\": [0.01, 0.05],\n",
    "            # \"max_features\": [0.5, 1.0]\n",
    "        }\n",
    "    },\n",
    "    \"som\": {\n",
    "        \"func\": som_anomaly,\n",
    "        \"params\": {\n",
    "            \"m\": [5],\n",
    "            \"n\": [5],\n",
    "            \"k\": [1],\n",
    "            \"train_quantile\": [0.99]\n",
    "            # \"m\": [5, 10],\n",
    "            # \"n\": [5, 10],\n",
    "            # \"k\": [1, 3],\n",
    "            # \"train_quantile\": [0.99, 0.995]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# --- Bestes Modell suchen ---\n",
    "results = []  # Liste für alle Ergebnisse\n",
    "\n",
    "for name, info in models.items():\n",
    "    func = info[\"func\"]\n",
    "    param_grid = info[\"params\"]\n",
    "\n",
    "    # Alle Parameterkombinationen\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    for combination in product(*values):\n",
    "        params = dict(zip(keys, combination))\n",
    "        \n",
    "        # Modell trainieren auf Trainingsdaten (nur Good)\n",
    "        func(\n",
    "            pd.DataFrame(X_train, columns=feature_cols),\n",
    "            feature_cols=feature_cols,\n",
    "            **params\n",
    "        )\n",
    "        \n",
    "        # Predictions auf Validation-Set\n",
    "        val_pred_df = func(\n",
    "            pd.DataFrame(X_val, columns=feature_cols),\n",
    "            feature_cols=feature_cols,\n",
    "            **params\n",
    "        )\n",
    "        \n",
    "        # Welche Spalte für Preds?\n",
    "        if name == \"zscore\":\n",
    "            y_val_pred = val_pred_df[\"is_anomaly_z\"].astype(int)\n",
    "        elif name == \"ocsvm\":\n",
    "            y_val_pred = val_pred_df[\"is_anomaly_ocsvm\"].astype(int)\n",
    "        elif name == \"iforest\":\n",
    "            y_val_pred = val_pred_df[\"is_anomaly_if\"].astype(int)\n",
    "        elif name == \"som\":\n",
    "            y_val_pred = val_pred_df[\"is_anomaly_som\"].astype(int)\n",
    "        \n",
    "        # F1-Score auf Validation\n",
    "        score = f1_score(y_val, y_val_pred)\n",
    "        \n",
    "        # Ergebnis speichern\n",
    "        results.append({\n",
    "            \"model\": name,\n",
    "            \"params\": params,\n",
    "            \"f1_score\": score\n",
    "        })\n",
    "\n",
    "# --- Alle Ergebnisse sortiert nach F1 ---\n",
    "results_df = pd.DataFrame(results).sort_values(\"f1_score\", ascending=False)\n",
    "best_result = results_df.iloc[0]\n",
    "\n",
    "print(f\"Bestes Modell: {best_result['model']} mit F1={best_result['f1_score']:.4f}\")\n",
    "print(f\"Beste Parameter: {best_result['params']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c19677d",
   "metadata": {},
   "source": [
    "# Nutzung Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7096c027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-11 22:59:19,413] A new study created in memory with name: no-name-953da453-25da-4cf2-aa4d-0d0cafd7b635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-11 22:59:19,499] Trial 0 finished with value: 0.08582731338149295 and parameters: {'threshold': 3.580325609877695}. Best is trial 0 with value: 0.08582731338149295.\n",
      "[I 2026-02-11 22:59:19,601] Trial 1 finished with value: 0.45617406822705747 and parameters: {'threshold': 2.335675047214754}. Best is trial 1 with value: 0.45617406822705747.\n",
      "[I 2026-02-11 22:59:19,666] Trial 2 finished with value: 0.07989646246764452 and parameters: {'threshold': 3.9032636786681696}. Best is trial 1 with value: 0.45617406822705747.\n",
      "[I 2026-02-11 22:59:19,722] Trial 3 finished with value: 0.08368489022815324 and parameters: {'threshold': 3.6855763481538526}. Best is trial 1 with value: 0.45617406822705747.\n",
      "[I 2026-02-11 22:59:19,782] Trial 4 finished with value: 0.5548006665812075 and parameters: {'threshold': 2.076954053324468}. Best is trial 4 with value: 0.5548006665812075.\n",
      "[I 2026-02-11 22:59:19,864] Trial 5 finished with value: 0.3308539125260339 and parameters: {'threshold': 3.013775668852462}. Best is trial 4 with value: 0.5548006665812075.\n",
      "[I 2026-02-11 22:59:19,986] Trial 6 finished with value: 0.07973077918716023 and parameters: {'threshold': 3.925296655117658}. Best is trial 4 with value: 0.5548006665812075.\n",
      "[I 2026-02-11 22:59:20,066] Trial 7 finished with value: 0.3084697186816502 and parameters: {'threshold': 3.1485042615593315}. Best is trial 4 with value: 0.5548006665812075.\n",
      "[I 2026-02-11 22:59:20,137] Trial 8 finished with value: 0.5529729035572107 and parameters: {'threshold': 2.1075143936656673}. Best is trial 4 with value: 0.5548006665812075.\n",
      "[I 2026-02-11 22:59:20,211] Trial 9 finished with value: 0.288161517283573 and parameters: {'threshold': 3.1794407395879665}. Best is trial 4 with value: 0.5548006665812075.\n",
      "[I 2026-02-11 22:59:20,283] Trial 10 finished with value: 0.4010535307517084 and parameters: {'threshold': 2.5469910011764645}. Best is trial 4 with value: 0.5548006665812075.\n",
      "[I 2026-02-11 22:59:20,352] Trial 11 finished with value: 0.5587840858292356 and parameters: {'threshold': 2.023253792614635}. Best is trial 11 with value: 0.5587840858292356.\n",
      "[I 2026-02-11 22:59:20,435] Trial 12 finished with value: 0.39174962400630237 and parameters: {'threshold': 2.610056159610428}. Best is trial 11 with value: 0.5587840858292356.\n",
      "[I 2026-02-11 22:59:20,510] Trial 13 finished with value: 0.5557902823122719 and parameters: {'threshold': 2.061560038796877}. Best is trial 11 with value: 0.5587840858292356.\n",
      "[I 2026-02-11 22:59:20,622] Trial 14 finished with value: 0.38265379628295637 and parameters: {'threshold': 2.667145874692974}. Best is trial 11 with value: 0.5587840858292356.\n",
      "[I 2026-02-11 22:59:20,690] Trial 15 finished with value: 0.5592084264283435 and parameters: {'threshold': 2.018922699896171}. Best is trial 15 with value: 0.5592084264283435.\n",
      "[I 2026-02-11 22:59:20,765] Trial 16 finished with value: 0.44449055820709693 and parameters: {'threshold': 2.356309112369709}. Best is trial 15 with value: 0.5592084264283435.\n",
      "[I 2026-02-11 22:59:20,818] Trial 17 finished with value: 0.3588768645802866 and parameters: {'threshold': 2.808119180031406}. Best is trial 15 with value: 0.5592084264283435.\n",
      "[I 2026-02-11 22:59:20,891] Trial 18 finished with value: 0.47694495226487915 and parameters: {'threshold': 2.3192820821365308}. Best is trial 15 with value: 0.5592084264283435.\n",
      "[I 2026-02-11 22:59:21,001] Trial 19 finished with value: 0.5324116342767706 and parameters: {'threshold': 2.289551700854951}. Best is trial 15 with value: 0.5592084264283435.\n",
      "[I 2026-02-11 22:59:21,004] A new study created in memory with name: no-name-794c842e-5f1e-4cc0-9cf0-9c508926870f\n",
      "[I 2026-02-11 22:59:24,214] Trial 0 finished with value: 0.03253911806543385 and parameters: {'nu': 0.019560697680030787, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 0 with value: 0.03253911806543385.\n",
      "[I 2026-02-11 22:59:35,487] Trial 1 finished with value: 0.17572702597906165 and parameters: {'nu': 0.14945663675623286, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 1 with value: 0.17572702597906165.\n",
      "[I 2026-02-11 22:59:54,846] Trial 2 finished with value: 0.3144720873786408 and parameters: {'nu': 0.17201504081833005, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 2 with value: 0.3144720873786408.\n",
      "[I 2026-02-11 23:00:45,978] Trial 3 finished with value: 0.31957831325301206 and parameters: {'nu': 0.17994072269356592, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 3 with value: 0.31957831325301206.\n",
      "[I 2026-02-11 23:00:55,090] Trial 4 finished with value: 0.05101592048553083 and parameters: {'nu': 0.029596750677536615, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 3 with value: 0.31957831325301206.\n",
      "[I 2026-02-11 23:01:24,171] Trial 5 finished with value: 0.21025475653015158 and parameters: {'nu': 0.11073449110091271, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 3 with value: 0.31957831325301206.\n",
      "[I 2026-02-11 23:02:06,405] Trial 6 finished with value: 0.2718386346004655 and parameters: {'nu': 0.14913067646885933, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 3 with value: 0.31957831325301206.\n",
      "[I 2026-02-11 23:02:30,020] Trial 7 finished with value: 0.1748211495765151 and parameters: {'nu': 0.09176832834059148, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 3 with value: 0.31957831325301206.\n",
      "[I 2026-02-11 23:02:52,266] Trial 8 finished with value: 0.14092881246986982 and parameters: {'nu': 0.11436099326122642, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 3 with value: 0.31957831325301206.\n",
      "[I 2026-02-11 23:03:13,604] Trial 9 finished with value: 0.1332685612501012 and parameters: {'nu': 0.10654503879527961, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 3 with value: 0.31957831325301206.\n",
      "[I 2026-02-11 23:03:45,175] Trial 10 finished with value: 0.22604967474866944 and parameters: {'nu': 0.19899320302668516, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 3 with value: 0.31957831325301206.\n",
      "[I 2026-02-11 23:04:41,783] Trial 11 finished with value: 0.35768634113910025 and parameters: {'nu': 0.1998354796831827, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 11 with value: 0.35768634113910025.\n",
      "[I 2026-02-11 23:05:38,540] Trial 12 finished with value: 0.3547694812402871 and parameters: {'nu': 0.19800080512945045, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 11 with value: 0.35768634113910025.\n",
      "[I 2026-02-11 23:06:32,007] Trial 13 finished with value: 0.33819241982507287 and parameters: {'nu': 0.18728314893904086, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 11 with value: 0.35768634113910025.\n",
      "[I 2026-02-11 23:07:12,507] Trial 14 finished with value: 0.27969645346135974 and parameters: {'nu': 0.1509818439217303, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 11 with value: 0.35768634113910025.\n",
      "[I 2026-02-11 23:07:28,346] Trial 15 finished with value: 0.11549893842887474 and parameters: {'nu': 0.06134865135154044, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 11 with value: 0.35768634113910025.\n",
      "[I 2026-02-11 23:08:13,403] Trial 16 finished with value: 0.30407571363150665 and parameters: {'nu': 0.16557463542308754, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 11 with value: 0.35768634113910025.\n",
      "[I 2026-02-11 23:09:09,984] Trial 17 finished with value: 0.3565937315198108 and parameters: {'nu': 0.19917480581826785, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 11 with value: 0.35768634113910025.\n",
      "[I 2026-02-11 23:09:31,938] Trial 18 finished with value: 0.15620553359683795 and parameters: {'nu': 0.13008932915858182, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 11 with value: 0.35768634113910025.\n",
      "[I 2026-02-11 23:09:52,374] Trial 19 finished with value: 0.15802141256535812 and parameters: {'nu': 0.08300786333675486, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 11 with value: 0.35768634113910025.\n",
      "[I 2026-02-11 23:09:52,374] A new study created in memory with name: no-name-ca97002a-865a-4ef6-89df-c66c765bdd5e\n",
      "[I 2026-02-11 23:10:11,851] Trial 0 finished with value: 0.033018026057469216 and parameters: {'n_estimators': 500, 'max_samples': 0.6888699459384096, 'contamination': 0.01661748345256254, 'max_features': 0.6284570057110517}. Best is trial 0 with value: 0.033018026057469216.\n",
      "[I 2026-02-11 23:10:19,850] Trial 1 finished with value: 0.18677106271919092 and parameters: {'n_estimators': 200, 'max_samples': 0.7897982433857653, 'contamination': 0.09953627658690196, 'max_features': 0.722081113439053}. Best is trial 1 with value: 0.18677106271919092.\n",
      "[I 2026-02-11 23:10:23,943] Trial 2 finished with value: 0.08827586206896551 and parameters: {'n_estimators': 100, 'max_samples': 0.538766530993791, 'contamination': 0.04760633822970658, 'max_features': 0.7799588312941427}. Best is trial 1 with value: 0.18677106271919092.\n",
      "[I 2026-02-11 23:10:32,214] Trial 3 finished with value: 0.023696257068485774 and parameters: {'n_estimators': 200, 'max_samples': 0.8851670496578672, 'contamination': 0.011518418595071328, 'max_features': 0.8431685198011576}. Best is trial 1 with value: 0.18677106271919092.\n",
      "[I 2026-02-11 23:10:40,001] Trial 4 finished with value: 0.03177720253503526 and parameters: {'n_estimators': 200, 'max_samples': 0.91053169129818, 'contamination': 0.01638935408064927, 'max_features': 0.548304340999655}. Best is trial 1 with value: 0.18677106271919092.\n",
      "[I 2026-02-11 23:10:51,802] Trial 5 finished with value: 0.07073786915236518 and parameters: {'n_estimators': 300, 'max_samples': 0.6385885830270828, 'contamination': 0.03807943880437702, 'max_features': 0.8935454294688833}. Best is trial 1 with value: 0.18677106271919092.\n",
      "[I 2026-02-11 23:10:55,895] Trial 6 finished with value: 0.09347882120457084 and parameters: {'n_estimators': 100, 'max_samples': 0.7298874742768516, 'contamination': 0.05065750277387899, 'max_features': 0.7399461172383002}. Best is trial 1 with value: 0.18677106271919092.\n",
      "[I 2026-02-11 23:11:11,439] Trial 7 finished with value: 0.03807829181494662 and parameters: {'n_estimators': 400, 'max_samples': 0.8323997425369578, 'contamination': 0.019261567145609657, 'max_features': 0.6643204505642113}. Best is trial 1 with value: 0.18677106271919092.\n",
      "[I 2026-02-11 23:11:24,040] Trial 8 finished with value: 0.16750473992251258 and parameters: {'n_estimators': 300, 'max_samples': 0.8062901255463929, 'contamination': 0.08935443196133673, 'max_features': 0.886940520111849}. Best is trial 1 with value: 0.18677106271919092.\n",
      "[I 2026-02-11 23:11:35,328] Trial 9 finished with value: 0.11797609966946351 and parameters: {'n_estimators': 300, 'max_samples': 0.6246313955072932, 'contamination': 0.06323521664341747, 'max_features': 0.7205554065078197}. Best is trial 1 with value: 0.18677106271919092.\n",
      "[I 2026-02-11 23:11:43,517] Trial 10 finished with value: 0.18483141480937218 and parameters: {'n_estimators': 200, 'max_samples': 0.9975442681721599, 'contamination': 0.09856088007497502, 'max_features': 0.9819125846803356}. Best is trial 1 with value: 0.18677106271919092.\n",
      "[I 2026-02-11 23:11:52,233] Trial 11 finished with value: 0.18070218512153205 and parameters: {'n_estimators': 200, 'max_samples': 0.9918775621338272, 'contamination': 0.09619663846055009, 'max_features': 0.9729755353015502}. Best is trial 1 with value: 0.18677106271919092.\n",
      "[I 2026-02-11 23:12:00,823] Trial 12 finished with value: 0.1430600818918693 and parameters: {'n_estimators': 200, 'max_samples': 0.986701851261658, 'contamination': 0.07646679157136131, 'max_features': 0.9803299302002979}. Best is trial 1 with value: 0.18677106271919092.\n",
      "[I 2026-02-11 23:12:05,030] Trial 13 finished with value: 0.1539612602876382 and parameters: {'n_estimators': 100, 'max_samples': 0.8011367648553702, 'contamination': 0.08132283326718451, 'max_features': 0.8019710999704703}. Best is trial 1 with value: 0.18677106271919092.\n",
      "[I 2026-02-11 23:12:20,454] Trial 14 finished with value: 0.18214519293655984 and parameters: {'n_estimators': 400, 'max_samples': 0.9131131260361007, 'contamination': 0.09728449426556983, 'max_features': 0.6506375974607641}. Best is trial 1 with value: 0.18677106271919092.\n",
      "[I 2026-02-11 23:12:27,716] Trial 15 finished with value: 0.13402754450789386 and parameters: {'n_estimators': 200, 'max_samples': 0.5170851553435114, 'contamination': 0.07178379512480994, 'max_features': 0.5704158773898601}. Best is trial 1 with value: 0.18677106271919092.\n",
      "[I 2026-02-11 23:12:44,191] Trial 16 finished with value: 0.1651391297167864 and parameters: {'n_estimators': 400, 'max_samples': 0.7598823244128908, 'contamination': 0.08777890625473823, 'max_features': 0.9179672407823795}. Best is trial 1 with value: 0.18677106271919092.\n",
      "[I 2026-02-11 23:12:48,469] Trial 17 finished with value: 0.12588592642591967 and parameters: {'n_estimators': 100, 'max_samples': 0.8678998851080545, 'contamination': 0.06741203410258818, 'max_features': 0.6897402877078719}. Best is trial 1 with value: 0.18677106271919092.\n",
      "[I 2026-02-11 23:13:00,545] Trial 18 finished with value: 0.18570496083550914 and parameters: {'n_estimators': 300, 'max_samples': 0.9516213279185798, 'contamination': 0.09915043495254867, 'max_features': 0.8194193264195373}. Best is trial 1 with value: 0.18677106271919092.\n",
      "[I 2026-02-11 23:13:12,504] Trial 19 finished with value: 0.15399950161973586 and parameters: {'n_estimators': 300, 'max_samples': 0.9424816417615054, 'contamination': 0.08209193851026494, 'max_features': 0.8226730889747338}. Best is trial 1 with value: 0.18677106271919092.\n",
      "[I 2026-02-11 23:13:12,504] A new study created in memory with name: no-name-fcf3001e-e990-4eff-aa91-83d56a43b7d5\n",
      "[I 2026-02-11 23:13:15,671] Trial 0 finished with value: 0.15039094992513724 and parameters: {'m': 13, 'n': 12, 'k': 3, 'train_quantile': 0.9192435122091211}. Best is trial 0 with value: 0.15039094992513724.\n",
      "[I 2026-02-11 23:13:17,107] Trial 1 finished with value: 0.07245873153779323 and parameters: {'m': 5, 'n': 10, 'k': 4, 'train_quantile': 0.9594593254057115}. Best is trial 0 with value: 0.15039094992513724.\n",
      "[I 2026-02-11 23:13:19,297] Trial 2 finished with value: 0.023199785848130632 and parameters: {'m': 10, 'n': 11, 'k': 2, 'train_quantile': 0.983278778322056}. Best is trial 0 with value: 0.15039094992513724.\n",
      "[I 2026-02-11 23:13:20,736] Trial 3 finished with value: 0.08216571527417402 and parameters: {'m': 7, 'n': 8, 'k': 5, 'train_quantile': 0.9553848577831384}. Best is trial 0 with value: 0.15039094992513724.\n",
      "[I 2026-02-11 23:13:24,019] Trial 4 finished with value: 0.009725348941918056 and parameters: {'m': 14, 'n': 13, 'k': 5, 'train_quantile': 0.9912956116791463}. Best is trial 0 with value: 0.15039094992513724.\n",
      "[I 2026-02-11 23:13:25,629] Trial 5 finished with value: 0.08175611442399101 and parameters: {'m': 8, 'n': 8, 'k': 2, 'train_quantile': 0.9546676774594405}. Best is trial 0 with value: 0.15039094992513724.\n",
      "[I 2026-02-11 23:13:27,765] Trial 6 finished with value: 0.0 and parameters: {'m': 9, 'n': 12, 'k': 2, 'train_quantile': 0.9980627549740887}. Best is trial 0 with value: 0.15039094992513724.\n",
      "[I 2026-02-11 23:13:29,275] Trial 7 finished with value: 0.14536048064085447 and parameters: {'m': 12, 'n': 5, 'k': 1, 'train_quantile': 0.9222610289357321}. Best is trial 0 with value: 0.15039094992513724.\n",
      "[I 2026-02-11 23:13:30,751] Trial 8 finished with value: 0.0486172274088427 and parameters: {'m': 8, 'n': 7, 'k': 5, 'train_quantile': 0.9717417390498948}. Best is trial 0 with value: 0.15039094992513724.\n",
      "[I 2026-02-11 23:13:33,113] Trial 9 finished with value: 0.18215977781408266 and parameters: {'m': 12, 'n': 10, 'k': 4, 'train_quantile': 0.9019220314323739}. Best is trial 9 with value: 0.18215977781408266.\n",
      "[I 2026-02-11 23:13:37,125] Trial 10 finished with value: 0.18352518572944732 and parameters: {'m': 15, 'n': 15, 'k': 4, 'train_quantile': 0.9014173723140819}. Best is trial 10 with value: 0.18352518572944732.\n",
      "[I 2026-02-11 23:13:40,722] Trial 11 finished with value: 0.18503712164477443 and parameters: {'m': 15, 'n': 14, 'k': 4, 'train_quantile': 0.9008022589747571}. Best is trial 11 with value: 0.18503712164477443.\n",
      "[I 2026-02-11 23:13:44,647] Trial 12 finished with value: 0.18589482266612312 and parameters: {'m': 15, 'n': 15, 'k': 4, 'train_quantile': 0.9001339928274262}. Best is trial 12 with value: 0.18589482266612312.\n",
      "[I 2026-02-11 23:13:48,515] Trial 13 finished with value: 0.13108960875052586 and parameters: {'m': 15, 'n': 15, 'k': 3, 'train_quantile': 0.9300344105962658}. Best is trial 12 with value: 0.18589482266612312.\n",
      "[I 2026-02-11 23:13:51,561] Trial 14 finished with value: 0.12009824680274414 and parameters: {'m': 12, 'n': 14, 'k': 4, 'train_quantile': 0.936106685313729}. Best is trial 12 with value: 0.18589482266612312.\n",
      "[I 2026-02-11 23:13:54,890] Trial 15 finished with value: 0.16387214008424877 and parameters: {'m': 14, 'n': 14, 'k': 3, 'train_quantile': 0.9125580587497331}. Best is trial 12 with value: 0.18589482266612312.\n",
      "[I 2026-02-11 23:13:57,571] Trial 16 finished with value: 0.11552162849872774 and parameters: {'m': 11, 'n': 13, 'k': 4, 'train_quantile': 0.937450866257472}. Best is trial 12 with value: 0.18589482266612312.\n",
      "[I 2026-02-11 23:14:01,398] Trial 17 finished with value: 0.1712030260669353 and parameters: {'m': 15, 'n': 15, 'k': 5, 'train_quantile': 0.9083345824510015}. Best is trial 12 with value: 0.18589482266612312.\n",
      "[I 2026-02-11 23:14:04,496] Trial 18 finished with value: 0.10887715113307207 and parameters: {'m': 13, 'n': 13, 'k': 4, 'train_quantile': 0.9415814927467259}. Best is trial 12 with value: 0.18589482266612312.\n",
      "[I 2026-02-11 23:14:08,064] Trial 19 finished with value: 0.14771590530176726 and parameters: {'m': 14, 'n': 14, 'k': 3, 'train_quantile': 0.9213198521734346}. Best is trial 12 with value: 0.18589482266612312.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bestes Modell: zscore mit F1=0.5592\n",
      "Beste Parameter: {'threshold': 2.018922699896171}\n"
     ]
    }
   ],
   "source": [
    "# --- Feature-Spalten ---\n",
    "feature_cols = X_train.columns if isinstance(X_train, pd.DataFrame) else range(X_train.shape[1])\n",
    "\n",
    "# --- Objective-Funktion für Optuna ---\n",
    "def objective(trial, model_name):\n",
    "    # Je nach Modell verschiedene Hyperparameter vorschlagen\n",
    "    if model_name == \"zscore\":\n",
    "        threshold = trial.suggest_float(\"threshold\", 2.0, 4.0)\n",
    "        params = {\"threshold\": threshold}\n",
    "        func = zscore_detect\n",
    "\n",
    "    elif model_name == \"ocsvm\":\n",
    "        nu = trial.suggest_float(\"nu\", 0.01, 0.2)\n",
    "        kernel = trial.suggest_categorical(\"kernel\", [\"rbf\", \"linear\"])\n",
    "        gamma = trial.suggest_categorical(\"gamma\", [\"scale\", \"auto\"])\n",
    "        params = {\"nu\": nu, \"kernel\": kernel, \"gamma\": gamma}\n",
    "        func = ocsvm_fit_predict\n",
    "\n",
    "    elif model_name == \"iforest\":\n",
    "        n_estimators = trial.suggest_int(\"n_estimators\", 100, 500, step=100)\n",
    "        max_samples = trial.suggest_float(\"max_samples\", 0.5, 1.0)\n",
    "        contamination = trial.suggest_float(\"contamination\", 0.01, 0.1)\n",
    "        max_features = trial.suggest_float(\"max_features\", 0.5, 1.0)\n",
    "        params = {\n",
    "            \"n_estimators\": n_estimators,\n",
    "            \"max_samples\": max_samples,\n",
    "            \"contamination\": contamination,\n",
    "            \"max_features\": max_features\n",
    "        }\n",
    "        func = iforest_fit_predict\n",
    "\n",
    "    elif model_name == \"som\":\n",
    "        m = trial.suggest_int(\"m\", 5, 15)\n",
    "        n = trial.suggest_int(\"n\", 5, 15)\n",
    "        k = trial.suggest_int(\"k\", 1, 5)\n",
    "        train_quantile = trial.suggest_float(\"train_quantile\", 0.9, 0.999)\n",
    "        params = {\"m\": m, \"n\": n, \"k\": k, \"train_quantile\": train_quantile}\n",
    "        func = som_anomaly\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model {model_name}\")\n",
    "\n",
    "    # --- Trainiere auf Good-Daten ---\n",
    "    func(pd.DataFrame(X_train, columns=feature_cols), feature_cols=feature_cols, **params)\n",
    "\n",
    "    # --- Predictions auf Validation ---\n",
    "    val_pred_df = func(pd.DataFrame(X_val, columns=feature_cols), feature_cols=feature_cols, **params)\n",
    "\n",
    "    if model_name == \"zscore\":\n",
    "        y_val_pred = val_pred_df[\"is_anomaly_z\"].astype(int)\n",
    "    elif model_name == \"ocsvm\":\n",
    "        y_val_pred = val_pred_df[\"is_anomaly_ocsvm\"].astype(int)\n",
    "    elif model_name == \"iforest\":\n",
    "        y_val_pred = val_pred_df[\"is_anomaly_if\"].astype(int)\n",
    "    elif model_name == \"som\":\n",
    "        y_val_pred = val_pred_df[\"is_anomaly_som\"].astype(int)\n",
    "\n",
    "    # --- F1-Score auf Validation (maximieren) ---\n",
    "    return f1_score(y_val, y_val_pred)\n",
    "\n",
    "# --- Hyperparameter-Optimierung pro Modell ---\n",
    "study_results = {}\n",
    "\n",
    "for model_name in models.keys():\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(lambda trial: objective(trial, model_name), n_trials=20)\n",
    "    study_results[model_name] = study\n",
    "\n",
    "# --- Bestes Modell finden ---\n",
    "best_model_name = None\n",
    "best_f1 = -1\n",
    "best_params = None\n",
    "\n",
    "for model_name, study in study_results.items():\n",
    "    if study.best_value > best_f1:\n",
    "        best_f1 = study.best_value\n",
    "        best_params = study.best_params\n",
    "        best_model_name = model_name\n",
    "\n",
    "print(f\"Bestes Modell: {best_model_name} mit F1={best_f1:.4f}\")\n",
    "print(f\"Beste Parameter: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7e4ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation für zscore:\n",
      "Parameters: {'threshold': 2.018922699896171}\n",
      "Accuracy: 0.4585189900275833\n",
      "Recall: 0.40396217185716615\n",
      "F1-Score: 0.5641580325629056\n",
      "Average Precision: 0.894746936918591\n"
     ]
    }
   ],
   "source": [
    "# --- Bestes Modell final trainieren ---\n",
    "if best_model_name == \"zscore\":\n",
    "    # Trainiere auf Trainingsdaten\n",
    "    final_model = zscore_detect(pd.DataFrame(X_train, columns=feature_cols), feature_cols=feature_cols, **best_params)\n",
    "    # Für Vorhersage auf Testdaten\n",
    "    def predict(X):\n",
    "        df = zscore_detect(pd.DataFrame(X, columns=feature_cols), feature_cols=feature_cols, **best_params)\n",
    "        return df[\"is_anomaly_z\"].astype(int)\n",
    "    def decision_function(X):\n",
    "        df = zscore_detect(pd.DataFrame(X, columns=feature_cols), feature_cols=feature_cols, **best_params)\n",
    "        return df[\"score_z\"]  # sofern deine Funktion einen Score liefert\n",
    "\n",
    "elif best_model_name == \"ocsvm\":\n",
    "    final_model = ocsvm_fit_predict(pd.DataFrame(X_train, columns=feature_cols), feature_cols=feature_cols, **best_params)\n",
    "    def predict(X):\n",
    "        df = ocsvm_fit_predict(pd.DataFrame(X, columns=feature_cols), feature_cols=feature_cols, **best_params)\n",
    "        return df[\"is_anomaly_ocsvm\"].astype(int)\n",
    "    def decision_function(X):\n",
    "        df = ocsvm_fit_predict(pd.DataFrame(X, columns=feature_cols), feature_cols=feature_cols, **best_params)\n",
    "        return df[\"score_ocsvm\"]\n",
    "\n",
    "elif best_model_name == \"iforest\":\n",
    "    final_model = iforest_fit_predict(pd.DataFrame(X_train, columns=feature_cols), feature_cols=feature_cols, **best_params)\n",
    "    def predict(X):\n",
    "        df = iforest_fit_predict(pd.DataFrame(X, columns=feature_cols), feature_cols=feature_cols, **best_params)\n",
    "        return df[\"is_anomaly_if\"].astype(int)\n",
    "    def decision_function(X):\n",
    "        df = iforest_fit_predict(pd.DataFrame(X, columns=feature_cols), feature_cols=feature_cols, **best_params)\n",
    "        return df[\"score_if\"]\n",
    "\n",
    "elif best_model_name == \"som\":\n",
    "    final_model = som_anomaly(pd.DataFrame(X_train, columns=feature_cols), feature_cols=feature_cols, **best_params)\n",
    "    def predict(X):\n",
    "        df = som_anomaly(pd.DataFrame(X, columns=feature_cols), feature_cols=feature_cols, **best_params)\n",
    "        return df[\"is_anomaly_som\"].astype(int)\n",
    "    def decision_function(X):\n",
    "        df = som_anomaly(pd.DataFrame(X, columns=feature_cols), feature_cols=feature_cols, **best_params)\n",
    "        return df[\"score_som\"]\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Unknown model {best_model_name}\")\n",
    "\n",
    "# --- Vorhersage auf Testdaten ---\n",
    "preds_test = predict(X_test)\n",
    "\n",
    "# --- Evaluation ---\n",
    "ap = average_precision_score(y_test, preds_test)\n",
    "accuracy = accuracy_score(y_test, preds_test)\n",
    "recall = recall_score(y_test, preds_test)\n",
    "f1 = f1_score(y_test, preds_test)\n",
    "\n",
    "print(f\"\\nEvaluation für {best_model_name}:\")\n",
    "print(\"Parameters:\", best_params)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"Average Precision:\", ap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "studium",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
